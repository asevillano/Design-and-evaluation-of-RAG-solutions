{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to end process\n",
    "\n",
    "This code demonstrate the complete process with the following tasks:\n",
    "1. Convert HTML files to markdown format\n",
    "2. Chunk markdown content with the maximum number of tokens specified\n",
    "3. Create the index and upload the chunks\n",
    "4. Test the search and answer generation creating the Excel files with the results of answers evaluation\n",
    "\n",
    "## Prerequisites\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
    "+ A Document Intelligence service with its end-point and API key.\n",
    "+ An Azure OpenAI service with the service name and an API key.\n",
    "+ A deployment of the text-embedding-ada-002 embedding model on the Azure OpenAI Service.\n",
    "+ An Azure AI Search service with the end-point, API Key and the index name to create.\n",
    "\n",
    "We used Python 3.12.3, [Visual Studio Code with the Python extension](https://code.visualstudio.com/docs/python/python-tutorial), and the [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) to test this example.\n",
    "\n",
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install azure-search-documents\n",
    "!pip install nbimporter\n",
    "!pip install nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and create AOAI and AI Search clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from pa_utils import load_files\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# AZURE AI SEARCH\n",
    "ai_search_endpoint = os.environ[\"SEARCH_SERVICE_ENDPOINT\"]\n",
    "ai_search_apikey = os.environ[\"SEARCH_SERVICE_QUERY_KEY\"]\n",
    "ai_search_index_name = os.environ[\"SEARCH_INDEX_NAME\"]\n",
    "ai_search_credential = AzureKeyCredential(ai_search_apikey)\n",
    "\n",
    "# CREATE AZURE AI SEARCH CLIENT\n",
    "ai_search_client = SearchClient(endpoint=ai_search_endpoint, index_name=ai_search_index_name, credential=ai_search_credential)\n",
    "\n",
    "aoai_api_version = '2024-02-15-preview'\n",
    "\n",
    "# AOAI FOR ANSWER GENERATION\n",
    "aoai_answer_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "aoai_answer_apikey = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "aoai_answer_model_name = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "# Create AOAI client for answer generation\n",
    "aoai_answer_client = AzureOpenAI(\n",
    "    azure_deployment=aoai_answer_model_name,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_answer_endpoint,\n",
    "    api_key=aoai_answer_apikey\n",
    ")\n",
    "\n",
    "# AZURE OPENAI FOR RERANKING\n",
    "aoai_rerank_endpoint = os.environ[\"AZURE_OPENAI_RERANK_ENDPOINT\"]\n",
    "azure_openai_rerank_key = os.environ[\"AZURE_OPENAI_RERANK_API_KEY\"]\n",
    "rerank_model_name = os.environ[\"AZURE_OPENAI_RERANK_DEPLOYMENT_NAME\"]\n",
    "# Create AOAI client for reranking\n",
    "aoai_rerank_client = AzureOpenAI(\n",
    "    azure_deployment=rerank_model_name,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_rerank_endpoint,\n",
    "    api_key=azure_openai_rerank_key\n",
    ")\n",
    "\n",
    "# AZURE OPENAI FOR EMBEDDING\n",
    "aoai_embedding_endpoint = os.environ[\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"]\n",
    "azure_openai_embedding_key = os.environ[\"AZURE_OPENAI_EMBEDDING_API_KEY\"]\n",
    "embedding_model_name_ada = os.environ[\"AZURE_OPENAI_EMBEDDING_NAME_ADA\"]\n",
    "embedding_model_name_large_3 = os.environ[\"AZURE_OPENAI_EMBEDDING_NAME_LARGE_3\"]\n",
    "# Create AOAI client for embedding creation (ADA)\n",
    "aoai_embedding_client_ada = AzureOpenAI(\n",
    "    azure_deployment=embedding_model_name_ada,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_embedding_endpoint,\n",
    "    api_key=azure_openai_embedding_key\n",
    ")\n",
    "# Create AOAI client for embedding creation (LARGE-3)\n",
    "aoai_embedding_client_large_3 = AzureOpenAI(\n",
    "    azure_deployment=embedding_model_name_large_3,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_embedding_endpoint,\n",
    "    api_key=azure_openai_embedding_key\n",
    ")\n",
    "\n",
    "# Prepare the tests\n",
    "TESTS = {\n",
    "        # Test-name: Embeddings_fields | uppercase/lowercase) | embbeding_model | index_name | max_retrieve | max_generate\n",
    "        \"title_content_ada_512_search_upper_20_10\": (\"embeddingTitle, embeddingContent\", \"upper\", \"ada\", \"project_assurance_ada_512\", 20, 10),\n",
    "        \"title_content_ada_512_search_upper_20_20\": (\"embeddingTitle, embeddingContent\", \"upper\", \"ada\", \"project_assurance_ada_512\", 20, 20),\n",
    "        \"title_content_ada_512_search_lower_20_10\": (\"embeddingTitle, embeddingContent\", \"lower\", \"ada\", \"project_assurance_ada_512\", 20, 10),\n",
    "        \"title_content_ada_512_search_lower_20_20\": (\"embeddingTitle, embeddingContent\", \"lower\", \"ada\", \"project_assurance_ada_512\", 20, 20),\n",
    "        \"title_content_large_3_512_search_upper_20_10\": (\"embeddingTitle, embeddingContent\", \"upper\", \"large-3\", \"project_assurance_large_3_512\", 20, 10),\n",
    "        \"title_content_large_3_512_search_upper_20_20\": (\"embeddingTitle, embeddingContent\", \"upper\", \"large-3\", \"project_assurance_large_3_512\", 20, 20),\n",
    "        \"title_content_large_3_512_search_lower_20_10\": (\"embeddingTitle, embeddingContent\", \"lower\", \"large-3\", \"project_assurance_large_3_512\", 20, 10),\n",
    "        \"title_content_large_3_512_search_lower_20_20\": (\"embeddingTitle, embeddingContent\", \"lower\", \"large-3\", \"project_assurance_large_3_512\", 20, 20),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For every HTML file in the input directory, convert to markdown format and chunk them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from convert_html_to_markdown import get_markdown_with_doc_intel\n",
    "from chunking_with_max_tokens import chunk_with_max_tokens\n",
    "from create_index_and_index_documents import create_index, index_documents\n",
    "from generate_synthetic_qa_pairs import generate_answers_and_questions\n",
    "from search_and_answer_generation_tests import execute_test\n",
    "import pandas as pd\n",
    "\n",
    "input_dir = 'html_files'\n",
    "html_files = load_files(input_dir, '.html')\n",
    "\n",
    "i=1\n",
    "all_chunks = []\n",
    "qa_data = {'question': [], 'answer': []}\n",
    "# Read the html files\n",
    "for i, html_file in enumerate(html_files):\n",
    "    print(f\"[{i + 1}]: {html_file['title']}\")\n",
    "    print(f\"\\t[{html_file['content']}]\")\n",
    "\n",
    "    # Convert the html files to markdown format\n",
    "    print(f'\\tConverting to markdown...')\n",
    "    markdown = get_markdown_with_doc_intel(chunk['content'])\n",
    "    print(f'markdown: [{markdown}]')\n",
    "    title = html_file['title'].replace('.html', '')\n",
    "\n",
    "    # Generate questions and answers pairs from the markdown content and prepare them to be salved in an Excel file\n",
    "    qa_pairs = generate_answers_and_questions(title + '. ' + markdown)\n",
    "    for qa in qa_pairs:\n",
    "        qa_data['question'].append(qa['question'])\n",
    "        qa_data['answer'].append(qa['answer'])\n",
    "\n",
    "    # Chunk the markdown content with a maximum number of tokens and a percentage of overlapping\n",
    "    chunks = chunk_with_max_tokens(markdown, 512, 0.25)\n",
    "\n",
    "    # Prepare the list of chunks to be indexed\n",
    "    for chunk in chunks:\n",
    "        new_row = {title, markdown}\n",
    "        all_chunks.append(new_row)\n",
    "\n",
    "# Save questions and answers pairs in an Excel file\n",
    "df = pd.DataFrame(qa_data)\n",
    "qa_output_file = 'qa_pairs_2.xlsx'\n",
    "df.to_excel(qa_output_file, index=False)\n",
    "print(f'File {qa_output_file} saved')\n",
    "\n",
    "# Create the index\n",
    "index_name = 'project_assurance_ada_512'\n",
    "create_index(index_name, embedding_model_name_ada)\n",
    "\n",
    "# Index the chunks\n",
    "index_documents(index_name, all_chunks)\n",
    "\n",
    "# Execute the tests\n",
    "for test_name, (embedding_fields, case, embbeding_model, index_name, max_retrieve, max_generate, qa_output_file) in TESTS.items():\n",
    "    execute_test(test_name, embedding_fields, case, embbeding_model, index_name, max_retrieve, max_generate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
