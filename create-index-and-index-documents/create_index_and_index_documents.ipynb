{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Azure AI Search index and upload documents\n",
    "\n",
    "This code demonstrate how to create the index and index documents, that is needed for the notebooks 'find_duplicates.ipynb' and 'rerank_chunks_and_generate_answer.ipynb'.\n",
    "\n",
    "The output is the index created in the Azure AI Service with documents indexed on it.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
    "+ An Azure OpenAI service with the service name and an API key.\n",
    "+ A deployment of the text-embedding-ada-002 embedding model on the Azure OpenAI Service.\n",
    "+ An Azure AI Search service with the end-point, API Key and the index name to create.\n",
    "\n",
    "We used Python 3.12.3, [Visual Studio Code with the Python extension](https://code.visualstudio.com/docs/python/python-tutorial), and the [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) to test this example.\n",
    "\n",
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai\n",
    "! pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and create AOAI and AI Search clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField, SearchFieldDataType, SearchableField, SearchField, VectorSearch, HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile, SemanticConfiguration, SemanticPrioritizedFields, SemanticField, SemanticSearch,\n",
    "    SearchIndex, VectorSearchAlgorithmKind, HnswParameters, VectorSearchAlgorithmMetric\n",
    ")\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import pa_utils\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# AZURE AI SEARCH\n",
    "ai_search_endpoint = os.environ[\"SEARCH_SERVICE_ENDPOINT\"]\n",
    "ai_search_apikey = os.environ[\"SEARCH_SERVICE_QUERY_KEY\"]\n",
    "ai_search_index_name = os.environ[\"SEARCH_INDEX_NAME\"]\n",
    "ai_search_credential = AzureKeyCredential(ai_search_apikey)\n",
    "\n",
    "# AZURE OPENAI FOR EMBEDDING\n",
    "aoai_embedding_endpoint = os.environ[\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"]\n",
    "azure_openai_embedding_key = os.environ[\"AZURE_OPENAI_EMBEDDING_API_KEY\"]\n",
    "embedding_model_name_ada = os.environ[\"AZURE_OPENAI_EMBEDDING_NAME_ADA\"]\n",
    "embedding_model_name_large_3 = os.environ[\"AZURE_OPENAI_EMBEDDING_NAME_LARGE_3\"]\n",
    "\n",
    "# AOAI client for embedding creation (ADA)\n",
    "aoai_api_version = '2024-02-15-preview'\n",
    "\n",
    "aoai_embedding_client_ada = AzureOpenAI(\n",
    "    azure_deployment=embedding_model_name_ada,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_embedding_endpoint,\n",
    "    api_key=azure_openai_embedding_key\n",
    ")\n",
    "\n",
    "aoai_embedding_client_large_3 = AzureOpenAI(\n",
    "    azure_deployment=embedding_model_name_large_3,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_embedding_endpoint,\n",
    "    api_key=azure_openai_embedding_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Azure AI Seach index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name, embedding_model_name):\n",
    "\n",
    "    # Create an Azure AI Search index client\n",
    "    index_client = SearchIndexClient(endpoint=ai_search_endpoint, credential=ai_search_credential)\n",
    "\n",
    "    if embedding_model_name == 'ada':\n",
    "        dimensions = 1536\n",
    "    else:\n",
    "        dimensions = 3072\n",
    "    # Fields definition\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "        SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "        SearchField(name=\"embeddingTitle\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    searchable=True, vector_search_dimensions=dimensions, vector_search_profile_name=\"myHnswProfile\"),\n",
    "        SearchField(name=\"embeddingContent\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    searchable=True, vector_search_dimensions=dimensions, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]\n",
    "\n",
    "    # Configure the vector search configuration  \n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\",\n",
    "                kind=VectorSearchAlgorithmKind.HNSW,\n",
    "                parameters=HnswParameters(\n",
    "                    m=4,\n",
    "                    ef_construction=400,\n",
    "                    ef_search=500,\n",
    "                    metric=VectorSearchAlgorithmMetric.COSINE\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Semantic ranker configuration\n",
    "    semantic_config = SemanticConfiguration(\n",
    "        name=\"semantic-config\",\n",
    "        prioritized_fields=SemanticPrioritizedFields(\n",
    "            title_field=SemanticField(field_name=\"title\"),\n",
    "            content_fields=[SemanticField(field_name=\"content\")]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the semantic settings with the configuration\n",
    "    semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "    # Create the search index with the semantic settings\n",
    "    index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)\n",
    "    result = index_client.create_or_update_index(index)\n",
    "    print(f'Index {result.name} created')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index documents in the Azure AI Search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the batch in Azure AI Search index\n",
    "def index_lote(batch_client, lote, i):\n",
    "    try:\n",
    "        print(f'Indexing until document {i}...')\n",
    "        batch_client.upload_documents(documents=lote)\n",
    "        print(f'Waiting 15 seconds...') \n",
    "        time.sleep(15)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "# Index the chunks in files\n",
    "def index_documents(index_name, embedding_model_name, chunk_contents):\n",
    "\n",
    "    # Create an index batch client\n",
    "    batch_client = SearchIndexingBufferedSender(\n",
    "                endpoint=ai_search_endpoint,\n",
    "                index_name=index_name,\n",
    "                credential=ai_search_credential\n",
    "            )\n",
    "\n",
    "    if embedding_model_name == 'ada':\n",
    "        embedding_client = aoai_embedding_client_ada\n",
    "    else:\n",
    "        embedding_client = aoai_embedding_client_large_3\n",
    "\n",
    "    lote=[]\n",
    "    for i, chunk_content in enumerate(chunk_contents): # Index the chunks using the file name as title\n",
    "        print('=================================================================')\n",
    "        title = chunk_content['title']\n",
    "        content = chunk_content['content']\n",
    "        print(f\"[{i + 1}]: title: {title}\")\n",
    "        print(f\"\\t[{content}]\")\n",
    "        document = {\n",
    "            \"id\": str(i),\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "            # Create embeddings with ADA-2\n",
    "            \"embeddingTitle\": embedding_client.embeddings.create(input=pa_utils.cut_max_tokens(title), model=embedding_model_name).data[0].embedding,\n",
    "            \"embeddingContent\": embedding_client.embeddings.create(input=pa_utils.cut_max_tokens(content), model=embedding_model_name).data[0].embedding,\n",
    "        }\n",
    "        # Add the document to the batch\n",
    "        lote.append(document)\n",
    "        # Index every 10 documents in the batch\n",
    "        if (i + 1) % 10 == 0:\n",
    "            # Upload documents\n",
    "            print(f'INDEXING BATCH {i + 1}')\n",
    "            index_lote(batch_client, lote, i)\n",
    "            lote = []\n",
    "\n",
    "    # Index the rest of documents after the last batch\n",
    "    if len(lote) > 0:\n",
    "        index_lote(batch_client, lote, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index\n",
    "create_index('project_assurance_large_3', 'large-3')\n",
    "\n",
    "# Read chunk files in markdown format in the input directory\n",
    "input_dir = '../data_out/chunk_files'\n",
    "chunk_contents = pa_utils.load_files(input_dir, '.txt')\n",
    "\n",
    "# Index the chunks\n",
    "index_documents('project_assurance_large_3', 'large-3', chunk_contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
